{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT-2 Text-Generating Model",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_"
      },
      "source": [
        "#  Train a GPT-2 Text-Generating Model w/ GPU For Free \n",
        "\n",
        "by [Max Woolf](http://minimaxir.com)\n",
        "\n",
        "*Last updated: November 10th, 2019*\n",
        "\n",
        "Retrain an advanced text generating neural network on any text dataset **for free on a GPU using Collaboratory** using `gpt-2-simple`!\n",
        "\n",
        "For more about `gpt-2-simple`, you can visit [this GitHub repository](https://github.com/minimaxir/gpt-2-simple). You can also read my [blog post](https://minimaxir.com/2019/09/howto-gpt2/) for more information how to use this notebook!\n",
        "\n",
        "\n",
        "To get started:\n",
        "\n",
        "1. Copy this notebook to your Google Drive to keep it and save your changes. (File -> Save a Copy in Drive)\n",
        "2. Make sure you're running the notebook in Google Chrome.\n",
        "3. Run the cells below:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "outputId": "66d9b26c-b0ab-4a3f-a2a4-33ca888be9e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj2IJLHP3KwE"
      },
      "source": [
        "## GPU\n",
        "\n",
        "Colaboratory uses either a Nvidia T4 GPU or an Nvidia K80 GPU. The T4 is slightly faster than the old K80 for training GPT-2, and has more memory allowing you to train the larger GPT-2 models and generate more text.\n",
        "\n",
        "You can verify which GPU is active by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUmTooTW3osf",
        "outputId": "c3d19dc2-b43f-48ac-e9c0-db091eeb5818",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Oct 23 20:23:07 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   68C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wXB05bPDYxS"
      },
      "source": [
        "## Downloading GPT-2\n",
        "\n",
        "If you're retraining a model on new text, you need to download the GPT-2 model first. \n",
        "\n",
        "There are three released sizes of GPT-2:\n",
        "\n",
        "* `124M` (default): the \"small\" model, 500MB on disk.\n",
        "* `355M`: the \"medium\" model, 1.5GB on disk.\n",
        "* `774M`: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model (see later in Notebook)\n",
        "* `1558M`: the \"extra large\", true model. Will not work if a K80 GPU is attached to the notebook. (like `774M`, it cannot be finetuned).\n",
        "\n",
        "Larger models have more knowledge, but take longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name` in the cells below.\n",
        "\n",
        "The next cell downloads it from Google Cloud Storage and saves it in the Colaboratory VM at `/models/<model_name>`.\n",
        "\n",
        "This model isn't permanently saved in the Colaboratory VM; you'll have to redownload it if you want to retrain it at a later time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR",
        "outputId": "168f47f8-40f0-478d-9760-842ca54b9dbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"355M\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 262Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 89.8Mit/s]                                                   \n",
            "Fetching hparams.json: 1.05Mit [00:00, 588Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:09, 152Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 173Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 148Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 186Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8KXuKWzQSsN"
      },
      "source": [
        "## Mounting Google Drive\n",
        "\n",
        "The best way to get input text to-be-trained into the Colaboratory VM, and to get the trained model *out* of Colaboratory, is to route it through Google Drive *first*.\n",
        "\n",
        "Running this cell (which will only work in Colaboratory) will mount your personal Google Drive in the VM, which later cells can use to get data in/out. (it will ask for an auth code; that auth is not saved anywhere)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puq4iC6vUAHc",
        "outputId": "ba54db05-e349-4492-cea1-52e3f76468eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT__brhBCvJu"
      },
      "source": [
        "## Uploading a Text File to be Trained to Colaboratory\n",
        "\n",
        "In the Colaboratory Notebook sidebar on the left of the screen, select *Files*. From there you can upload files:\n",
        "\n",
        "![alt text](https://i.imgur.com/TGcZT4h.png)\n",
        "\n",
        "Upload **any smaller text file**  (<10 MB) and update the file name in the cell below, then run the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll"
      },
      "source": [
        "file_name = \"input_ALL.txt\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vng4tvv4ej5P",
        "outputId": "77b58467-5907-4850-c9dc-8325bfc179f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeeSKtNWUedE"
      },
      "source": [
        "If your text file is larger than 10MB, it is recommended to upload that file to Google Drive first, then copy that file from Google Drive to the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z6okFD8VKtS"
      },
      "source": [
        "gpt2.copy_file_from_gdrive(file_name)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3"
      },
      "source": [
        "## Finetune GPT-2\n",
        "\n",
        "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
        "\n",
        "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps (can be changed) and when the cell is stopped.\n",
        "\n",
        "The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them!\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files.\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.finetune`:\n",
        "\n",
        "\n",
        "*  **`restore_from`**: Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n",
        "* **`sample_every`**: Number of steps to print example output\n",
        "* **`print_every`**: Number of steps to print training progress.\n",
        "* **`learning_rate`**:  Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n",
        "*  **`run_name`**: subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)\n",
        "* **`overwrite`**: Set to `True` if you want to continue finetuning an existing model (w/ `restore_from='latest'`) without creating duplicate copies. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXshJM-Cuaf",
        "outputId": "20afc02e-ac4f-45cf-87ca-e240b75953b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='355M',\n",
        "              steps=500,\n",
        "              restore_from='fresh',\n",
        "              run_name='run_all_10_23_short',\n",
        "              print_every=10,\n",
        "              sample_every=200,\n",
        "              save_every=500\n",
        "              )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/memory_saving_gradients.py:62: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.\n",
            "Instructions for updating:\n",
            "Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.\n",
            "Loading checkpoint models/355M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/355M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:08<00:00,  8.66s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 1742394 tokens\n",
            "Training...\n",
            "[10 | 23.70] loss=3.72 avg=3.72\n",
            "[20 | 39.89] loss=3.51 avg=3.62\n",
            "[30 | 56.50] loss=3.22 avg=3.48\n",
            "[40 | 73.19] loss=3.51 avg=3.49\n",
            "[50 | 89.56] loss=3.05 avg=3.40\n",
            "[60 | 105.83] loss=4.31 avg=3.56\n",
            "[70 | 122.11] loss=3.34 avg=3.52\n",
            "[80 | 138.52] loss=3.32 avg=3.50\n",
            "[90 | 155.02] loss=2.74 avg=3.41\n",
            "[100 | 171.43] loss=3.52 avg=3.42\n",
            "[110 | 187.78] loss=3.53 avg=3.43\n",
            "[120 | 204.18] loss=3.40 avg=3.43\n",
            "[130 | 220.59] loss=3.50 avg=3.44\n",
            "[140 | 237.08] loss=3.58 avg=3.45\n",
            "[150 | 253.57] loss=3.59 avg=3.46\n",
            "[160 | 269.96] loss=3.78 avg=3.48\n",
            "[170 | 286.37] loss=2.95 avg=3.44\n",
            "[180 | 302.79] loss=2.97 avg=3.42\n",
            "[190 | 319.21] loss=3.04 avg=3.39\n",
            "[200 | 335.62] loss=3.04 avg=3.37\n",
            "======== SAMPLE 1 ========\n",
            " , friends , and family . One of my nieces had a heart attack in January and needed to go to the hospital for several months , but my family decided to keep me in their home .\n",
            "A few days later , my phone call came , and someone said I was going to the funeral . I had to get off before the other guests even got here . The car was parked in front , so I stepped out on the grass , and when I got out , the driver was like \" Oh ! you are dead already !\n",
            "I got to go home with friends ! It was a whole new experience . I went through two different airports , I had to give up my travel privileges for a friend , then I got picked up by the person picking me up from home . It 's a bit of a pain in the ass , but a lot of fun .\n",
            "I saw a big box of these beautiful little tea cups , just about the right size for my daughter to hold . As I was sorting through the tea cups , I could not quite place it . It seemed to be round in shape but it was probably teak , not brown .\n",
            "I had to get my family together this afternoon . The house was so cool that I spent an hour or two in it - it was cool in all of the windows and my sister got there in time to see what I was up to . We were just chilling , talking , and just playing .\n",
            "C'mon . Let 's just get it moving . She's going to be so happy when she can ride this thing . I wonder how much she can afford to take . I wonder if she will want to buy one for her birthday . The whole \" she 'll tell me after I take it overdrive \" thing is just a lie I am trying to pull . Is it really a very big deal ...\n",
            "The day was cloudy and rainy , and with no snow .\n",
            "And he was a doctor . He was standing in front of a pile of corpses , and he was holding a vial filled with a thick, white liquid . He looked sick . I took the vial out , knowing that if I got any sickness , it would happen too fast to notice . I looked at my daughter . I saw that she too was in pain , and that every one of them had the same problem . I took that vial out , realizing that the person holding the vial was dead .\n",
            "I was so excited to be spending time with my friends , and meeting our family for the first time , and I was so excited to be in the park with my friends , I got all excited . I came to the park with my friend and I was wearing rain hair , and as I walked by the boys in the rain hair we stopped , and I was holding a little blue umbrella . I looked at them .\n",
            "Our server was really helpful as well and we were able to install and use the cool new features that you guys helped them add . We took a load from the weather and a bunch more from other things : it was great to see it all come together .\n",
            "It was so fun to get out and play the little old lady . . Her favorite place was in the park , and as we walked the playground , we could see flowers . The old ladies had a few new babies who seemed to be growing up very quickly . It was amazing to see them all , from 1 month old to 2 years old . It was just wonderful to see them being active .\n",
            "The kids would look at her funny and ask , \" Can we take you to the beach today ? \" and the thing is , I can take them to the beach but I ' m going to take them up to the beach in the morning . This was my first time to go surfing , and I was so glad to finally be able to do that in the warm weather ! I got back from the beach feeling so awesome ( as though the surf was beating all of my other memories ... which were some pretty cool memories with my family and that one time I was fishing ... ) and then there was lunch with my wife , and I had to go off to my car , because my car had broken down , and I couldn 't find my keys , so my wife and myself went home to make it seem like we 're still alive .\n",
            "I had a huge pain in my neck from the time I stopped drinking beer to the time I had taken it off to drink wine I had found at a friend 's house . I had this feeling where the pressure from the pain would come in through the cracks in my back ; I felt something was going through my neck. My parents and I did not want to let it go and said , \" You know what ? You know what ? \" we would say softly .\n",
            "I was thinking to myself , I really wonder how I would feel having done the same thing in my own skin . But instead what I did was take the pain away . Then it was like I had been playing the game for a week and I ' m\n",
            "\n",
            "[210 | 376.50] loss=3.65 avg=3.39\n",
            "[220 | 392.96] loss=3.15 avg=3.38\n",
            "[230 | 409.39] loss=2.98 avg=3.36\n",
            "[240 | 425.80] loss=2.97 avg=3.34\n",
            "[250 | 442.27] loss=3.38 avg=3.34\n",
            "[260 | 458.72] loss=2.87 avg=3.32\n",
            "[270 | 475.28] loss=3.07 avg=3.31\n",
            "[280 | 491.83] loss=2.90 avg=3.29\n",
            "[290 | 508.37] loss=3.17 avg=3.29\n",
            "[300 | 524.91] loss=3.57 avg=3.30\n",
            "[310 | 541.40] loss=2.95 avg=3.29\n",
            "[320 | 557.82] loss=2.95 avg=3.27\n",
            "[330 | 574.31] loss=3.62 avg=3.29\n",
            "[340 | 590.85] loss=2.90 avg=3.27\n",
            "[350 | 607.35] loss=3.20 avg=3.27\n",
            "[360 | 623.84] loss=2.88 avg=3.26\n",
            "[370 | 640.29] loss=3.61 avg=3.27\n",
            "[380 | 656.80] loss=3.66 avg=3.28\n",
            "[390 | 673.37] loss=3.53 avg=3.29\n",
            "[400 | 689.82] loss=2.96 avg=3.28\n",
            "======== SAMPLE 1 ========\n",
            " Cameron's voice in his mind .\n",
            "But what could they do ? They would be up and on their own and I 'd be the only one of them with me in the house . But anyway , there , I had the chance to get the most expensive watch ever . And in the end , it 's a Patek Philippe .\n",
            "He was so thrilled when he was told he would be making a new pet to put in my office . ( Or it is his pet or his pet may have been left - as in it would be in the office ? ) I love cats ; there 's nothing like putting some money down to buy one for your pet , and seeing it come or not . I ' m sure my son would have been happy . I was just so happy to put my money down and to see it come to life . At least the dogs would be happy to see their \" owner \" .\n",
            "I ' ve talked about this many occasions , but this is the first time we ' ve done it , but it 's well worth the time to tell both of them about . It is the first time we have shared the details with them . It 's also the first time we have actually shown them how and why they have caused us any problems .\n",
            "And we would go out to dinner each night . We would have a great time and just spend time with each other . The other people we talked to were so fun . They were so nice , I thought to myself I 'd make this a good week . But the reality turned out to be a lot grander than that .\n",
            "I was so excited to go to my first ever convention but when I walked through the door , I couldn 't quite believe what we saw . I felt so bad and so happy . I had talked so much about my previous experiences , but now it was my first con ever !\n",
            "We were there for hours , listening to some of the best music that you 'll find on the festival this year , and enjoying the amazing food and drinks . You would never know the night had started until you walked in , or walked out . It felt right , the whole place was nice , especially the art , and the people .\n",
            "You would be very surprised how far and wide the space was left for parking . With the lack of a curb and a lot of parking on one street , you really have a few choices to drive with . It is also very crowded in that part of the street . This was definitely one of those mornings where it felt like you were stepping into the middle of a parking lot and it would be hard to get to your place on time . The light was still on , but there was enough space for a couple vehicles , and even better for a couple cars and a van . This was quite enjoyable , very nice , but you 'll just have to take this one for a spin ( maybe if only to get enough oxygen and to see if it 'll give you enough space at least ) .\n",
            "I did not get all my ideas from my friend who wanted to do an early lunch and a late dinner . They just knew we were going to go in and get our lunch at McDonalds for lunch . We also did not have the time to buy a car on campus , so I decided to buy some cheap clothes and a cheap purse at the store last . I also decided to use the cheap clothes and the cheap purse to make lunch , dinner , and that would have been pretty good .\n",
            "There were a couple of other characters on the floor . I guess it was some kind of battle but I was never there nor did have anybody else there . One character that i could see is the guy who was in his 20s ( about 6 months ) with a tattoo on his neck . He has a weird haircut .\n",
            "He came over last night and got drunk , so i wanted that out , but we were having so much fun ! I will definitely go home and try to watch a tv series now or sometime , but i have yet to get that job done .\n",
            "We are still figuring out our route , and getting all the details done , but there are now two routes planned . Our planned route goes from a small town called Brandywine, to a major industrial site near a city called Piedmont . The main routes go from the major highway near Piedmont to the small section below it in Brandywine County . The alternative route goes through Piedmont , but there is a section of I-75 ( which I do n't plan on taking ) from the Piedmont highway , to the town called Brandywine .\n",
            "He called me and said he needed to do another job at a certain time , and if I did n't join him , he would leave the club or his job . I agreed with him that I 'd have to go anyway so it could have another shot at him . He told me he 'd do it for sure if I 'd agree with him . I said that was fine with me . I knew that\n",
            "\n",
            "[410 | 728.52] loss=3.04 avg=3.27\n",
            "[420 | 744.96] loss=2.92 avg=3.26\n",
            "[430 | 761.46] loss=2.74 avg=3.25\n",
            "[440 | 777.98] loss=3.82 avg=3.26\n",
            "[450 | 794.48] loss=3.70 avg=3.28\n",
            "[460 | 810.93] loss=3.28 avg=3.28\n",
            "[470 | 827.41] loss=3.73 avg=3.29\n",
            "[480 | 843.87] loss=2.82 avg=3.28\n",
            "[490 | 860.35] loss=3.23 avg=3.27\n",
            "[500 | 876.76] loss=3.45 avg=3.28\n",
            "Saving checkpoint/run_all_10_23_short/model-500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXSuTNERaw6K"
      },
      "source": [
        "After the model is trained, you can copy the checkpoint folder to your own Google Drive.\n",
        "\n",
        "If you want to download it to your personal computer, it's strongly recommended you copy it there first, then download from Google Drive. The checkpoint folder is copied as a `.rar` compressed file; you can download it and uncompress it locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHdTL8NDbAh3"
      },
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='run_all_10_22')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQJgV_b4bmzd"
      },
      "source": [
        "You're done! Feel free to go to the **Generate Text From The Trained Model** section to generate text based on your retrained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pel-uBULXO2L"
      },
      "source": [
        "## Load a Trained Model Checkpoint\n",
        "\n",
        "Running the next cell will copy the `.rar` checkpoint file from your Google Drive into the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCcx5u7sbPTD"
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run_all_10_22')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTa6zf3e_9gV"
      },
      "source": [
        "The next cell will allow you to load the retrained model checkpoint + metadata necessary to generate text.\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxL77nvAMAX",
        "outputId": "32381e2f-7a7e-4575-885f-a1387058c109",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run_all_10_23_short')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint checkpoint/run_all_10_22/model-1000\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/run_all_10_22/model-1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp"
      },
      "source": [
        "## Generate Text From The Trained Model\n",
        "\n",
        "Generate 2 datasets of 1000 samples. One with 50 tokens per sample and one with 100 tokens per sample.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RNY6RBI9LmL"
      },
      "source": [
        "text_50 = gpt2.generate(sess, run_name='run_all_10_23_short',length=50,return_as_list=True, nsamples=1000,batch_size=5,truncate='<|endoftext|>')\n",
        "text_100 = gpt2.generate(sess, run_name='run_all_10_23_short',length=100,return_as_list=True, nsamples=1000,batch_size=5,truncate='<|endoftext|>')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDeu5zDN0QZG",
        "outputId": "42de2ffa-c4ce-4c1b-9e9b-fc1186eb82c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_50 = pd.DataFrame(text_50,columns=['context'])\n",
        "df_100 = pd.DataFrame(text_100,columns=['context'])\n",
        "print(df_50.columns)\n",
        "print(df_100.columns)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['context'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdp2TtU80XzA"
      },
      "source": [
        "df.to_csv(\"context_50_ALL.csv\")\n",
        "df.to_csv(\"context_100_ALL.csv\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmTXWNUygS5E"
      },
      "source": [
        "# LICENSE\n",
        "\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2019 Max Woolf\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    }
  ]
}